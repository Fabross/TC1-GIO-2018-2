{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def f(A,X):\n",
    "    m=A.shape[0]\n",
    "    n=A.shape[1]\n",
    "    suMa = 0\n",
    "    suNa = 0\n",
    "    Iesimo = 0\n",
    "    for i in range(0,m):\n",
    "        Iesimo = 1-A[i,:]*X\n",
    "        if (Iesimo > 0):\n",
    "            suMa += -log(Iesimo)\n",
    "        else:\n",
    "            return nan\n",
    "    for i in range(0,n):\n",
    "        Iesimo = 1-power(X[i,0],2)\n",
    "        if (Iesimo > 0):\n",
    "            suNa += -log(Iesimo)\n",
    "        else:\n",
    "            return nan\n",
    "    return (suMa+suNa)\n",
    "\n",
    "def gradf(A,X):\n",
    "    m=A.shape[0]\n",
    "    n=A.shape[1]\n",
    "    suMai = matrix(zeros((n,1)))\n",
    "    suNai = matrix(zeros((n,1)))\n",
    "    for j in range(0,n):\n",
    "        for i in range(0,m):\n",
    "            suMai[j,0] += A[i,j]/(1-A[i,:]*X)\n",
    "    for i in range(0,n):\n",
    "        suNai[i,0] += 2*X[i,0]/(1-power(X[i],2))\n",
    "    return (suMai+suNai)\n",
    "\n",
    "def gradf2(A,X):\n",
    "    n=A.shape[1]\n",
    "    suMai = matrix(zeros((n,n)))\n",
    "    for j in range(0,n):\n",
    "        for i in range(0,n):\n",
    "            if (i==j):\n",
    "                suMai[j,i] += power(A[i,j]/(1-A[i,:]*X),2) + (2+2*power(X[i],2))/power((1-power(X[i],2)),2)\n",
    "    return (suMai)\n",
    "\n",
    "def gradiente_backtracking(A,X0,m,n,alfa,beta):\n",
    "    # inicializacion k=0\n",
    "    i = 0\n",
    "    XK = X0\n",
    "    print(\"iteracion: \"+str(i)+\", cond. de parada: \"+str(linalg.norm(gradf(A,XK))))\n",
    "    while (linalg.norm(gradf(A,XK))>1e-3):\n",
    "        i+=1\n",
    "        # Determinar deltaX^k\n",
    "        deltaXK = -gradf(A,XK)\n",
    "        # Determinar t con Back Tracking Search\n",
    "        tK = 1\n",
    "        # Si se sale del dominio con el t=1\n",
    "        while ~(isfinite(f(A,XK+tK*deltaXK))):\n",
    "            tK = 0.9*tK\n",
    "        while (f(A,XK+tK*deltaXK) > f(A,XK)+alfa*tK*gradf(A,XK).transpose()*deltaXK):\n",
    "            tK = beta*tK\n",
    "        t = tK\n",
    "        # Calculo de X(k+1)\n",
    "        XK1 = XK + tK*deltaXK\n",
    "        XK = XK1\n",
    "        print(\"iteracion: \"+str(i)+\", tK=\"+str(t)+\", cond. de parada: \"+str(linalg.norm(gradf(A,XK)))+\", funcion objetivo: \"+str(f(A,XK)))\n",
    "        \n",
    "def newton_backtracking(A,X0,m,n,alfa,beta):\n",
    "    # inicializacion k=0\n",
    "    i = 0\n",
    "    XK = X0\n",
    "    print(\"iteracion: \"+str(i)+\", cond. de parada: \"+str(linalg.norm(gradf(A,XK))))\n",
    "    while (True):\n",
    "        i+=1\n",
    "        # Determinar deltaX^k\n",
    "        deltaXK = -linalg.inv(gradf2(A,XK))*gradf(A,XK)\n",
    "        # Criterio de parada\n",
    "        lambda2 = -gradf(A,XK).transpose()*deltaXK\n",
    "        if (lambda2 <= 1e-8):\n",
    "            break\n",
    "        # Determinar t con Back Tracking Search\n",
    "        tK = 1\n",
    "        # Si se sale del dominio con el t=1\n",
    "        while ~(isfinite(f(A,XK+tK*deltaXK))):\n",
    "            tK = 0.9*tK\n",
    "        while (f(A,XK+tK*deltaXK) > f(A,XK)+alfa*tK*gradf(A,XK).transpose()*deltaXK):\n",
    "            tK = beta*tK\n",
    "        t = tK\n",
    "        # Calculo de X(k+1)\n",
    "        XK1 = XK + tK*deltaXK\n",
    "        XK = XK1\n",
    "        print(\"iteracion: \"+str(i)+\", tK=\"+str(t)+\", cond. de parada: \"+str(lambda2)+\", funcion objetivo: \"+str(f(A,XK)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "instancia 1 Metodo del gradiente con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 78.78590913682079\n",
      "iteracion: 1, tK=0.030903154382632643, cond. de parada: 10.265345035346607, funcion objetivo: [[-68.39545745]]\n",
      "iteracion: 2, tK=0.00938091470606245, cond. de parada: 3.9046694434137055, funcion objetivo: [[-68.86590811]]\n",
      "iteracion: 3, tK=0.0375236588242498, cond. de parada: 0.6998344634372842, funcion objetivo: [[-69.18567037]]\n",
      "iteracion: 4, tK=0.03690562500000001, cond. de parada: 0.17738099593797346, funcion objetivo: [[-69.19384314]]\n",
      "iteracion: 5, tK=0.03125, cond. de parada: 0.050292269052584895, funcion objetivo: [[-69.19422709]]\n",
      "iteracion: 6, tK=0.03125, cond. de parada: 0.017450671880101007, funcion objetivo: [[-69.19425334]]\n",
      "iteracion: 7, tK=0.03125, cond. de parada: 0.005987760737438966, funcion objetivo: [[-69.19425649]]\n",
      "iteracion: 8, tK=0.03125, cond. de parada: 0.002076376772868966, funcion objetivo: [[-69.19425686]]\n",
      "iteracion: 9, tK=0.03125, cond. de parada: 0.0007185503327095755, funcion objetivo: [[-69.1942569]]\n",
      "------------------------------------------------------\n",
      "instancia 1 Metodo de Newton con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 78.78590913682079\n",
      "iteracion: 1, tK=0.07178979876918531, cond. de parada: [[2757.77871795]], funcion objetivo: [[-68.23715639]]\n",
      "iteracion: 2, tK=0.5, cond. de parada: [[2.0230931]], funcion objetivo: [[-68.92869479]]\n",
      "iteracion: 3, tK=1, cond. de parada: [[0.39230722]], funcion objetivo: [[-69.1608552]]\n",
      "iteracion: 4, tK=1, cond. de parada: [[0.06032439]], funcion objetivo: [[-69.19342886]]\n",
      "iteracion: 5, tK=1, cond. de parada: [[0.00163197]], funcion objetivo: [[-69.19425635]]\n",
      "iteracion: 6, tK=1, cond. de parada: [[1.11663673e-06]], funcion objetivo: [[-69.19425691]]\n",
      "------------------------------------------------------\n",
      "instancia 2 Metodo del gradiente con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 351.6748678631505\n",
      "iteracion: 1, tK=0.004105800817065169, cond. de parada: 54.79146845180048, funcion objetivo: [[-178.09331979]]\n",
      "iteracion: 2, tK=0.04431469059826254, cond. de parada: 12.930213634199948, funcion objetivo: [[-250.04774208]]\n",
      "iteracion: 3, tK=0.10294556604732455, cond. de parada: 5.287060931007059, funcion objetivo: [[-256.47704153]]\n",
      "iteracion: 4, tK=0.0625, cond. de parada: 0.5426633331106665, funcion objetivo: [[-257.21258694]]\n",
      "iteracion: 5, tK=0.0625, cond. de parada: 0.0901122381377416, funcion objetivo: [[-257.22308935]]\n",
      "iteracion: 6, tK=0.0625, cond. de parada: 0.022898634328485483, funcion objetivo: [[-257.22340197]]\n",
      "iteracion: 7, tK=0.125, cond. de parada: 0.009747131575119205, funcion objetivo: [[-257.22342254]]\n",
      "iteracion: 8, tK=0.0625, cond. de parada: 0.002282694351006506, funcion objetivo: [[-257.22342617]]\n",
      "iteracion: 9, tK=0.0625, cond. de parada: 0.0006434977596521011, funcion objetivo: [[-257.22342637]]\n",
      "------------------------------------------------------\n",
      "instancia 2 Metodo de Newton con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 351.6748678631505\n",
      "iteracion: 1, tK=0.00858420955073129, cond. de parada: [[52853.71669151]], funcion objetivo: [[-169.19811609]]\n",
      "iteracion: 2, tK=0.0926510094425921, cond. de parada: [[1657.77052685]], funcion objetivo: [[-249.31273324]]\n",
      "iteracion: 3, tK=0.5, cond. de parada: [[35.73043907]], funcion objetivo: [[-256.8878038]]\n",
      "iteracion: 4, tK=1, cond. de parada: [[0.79715444]], funcion objetivo: [[-257.21482557]]\n",
      "iteracion: 5, tK=1, cond. de parada: [[0.02312568]], funcion objetivo: [[-257.22235549]]\n",
      "iteracion: 6, tK=1, cond. de parada: [[0.00282373]], funcion objetivo: [[-257.22331919]]\n",
      "iteracion: 7, tK=1, cond. de parada: [[0.00028498]], funcion objetivo: [[-257.22341473]]\n",
      "iteracion: 8, tK=1, cond. de parada: [[3.09116028e-05]], funcion objetivo: [[-257.22342516]]\n",
      "iteracion: 9, tK=1, cond. de parada: [[3.27772133e-06]], funcion objetivo: [[-257.22342626]]\n",
      "iteracion: 10, tK=1, cond. de parada: [[3.50168889e-07]], funcion objetivo: [[-257.22342638]]\n",
      "iteracion: 11, tK=1, cond. de parada: [[3.7318473e-08]], funcion objetivo: [[-257.22342639]]\n",
      "------------------------------------------------------\n",
      "instancia 3 Metodo del gradiente con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 993.67741723442\n",
      "iteracion: 1, tK=0.0010909954460109653, cond. de parada: 153.3421783097619, funcion objetivo: [[-369.43431284]]\n",
      "iteracion: 2, tK=0.02616738165136805, cond. de parada: 23.939951504229672, funcion objetivo: [[-623.69232472]]\n",
      "iteracion: 3, tK=0.08338590849833288, cond. de parada: 2.3994008623046015, funcion objetivo: [[-647.57357563]]\n",
      "iteracion: 4, tK=0.0625, cond. de parada: 0.3676907859690071, funcion objetivo: [[-647.7569495]]\n",
      "iteracion: 5, tK=0.0625, cond. de parada: 0.11422874240201865, funcion objetivo: [[-647.76243495]]\n",
      "iteracion: 6, tK=0.125, cond. de parada: 0.041939447729116446, funcion objetivo: [[-647.76296115]]\n",
      "iteracion: 7, tK=0.0625, cond. de parada: 0.012679421152049022, funcion objetivo: [[-647.76303252]]\n",
      "iteracion: 8, tK=0.125, cond. de parada: 0.004862804925984787, funcion objetivo: [[-647.76303878]]\n",
      "iteracion: 9, tK=0.0625, cond. de parada: 0.0014640098037067577, funcion objetivo: [[-647.76303974]]\n",
      "iteracion: 10, tK=0.125, cond. de parada: 0.0005735956930232828, funcion objetivo: [[-647.76303982]]\n",
      "------------------------------------------------------\n",
      "instancia 3 Metodo de Newton con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 993.67741723442\n",
      "iteracion: 1, tK=0.0022810004539250937, cond. de parada: [[436668.23343373]], funcion objetivo: [[-356.46044584]]\n",
      "iteracion: 2, tK=0.0492385451091806, cond. de parada: [[13001.47736301]], funcion objetivo: [[-618.8511738]]\n",
      "iteracion: 3, tK=0.36450000000000005, cond. de parada: [[159.70611429]], funcion objetivo: [[-647.67373139]]\n",
      "iteracion: 4, tK=1, cond. de parada: [[0.22652443]], funcion objetivo: [[-647.75691785]]\n",
      "iteracion: 5, tK=1, cond. de parada: [[0.01644011]], funcion objetivo: [[-647.76230366]]\n",
      "iteracion: 6, tK=1, cond. de parada: [[0.00195109]], funcion objetivo: [[-647.76296257]]\n",
      "iteracion: 7, tK=1, cond. de parada: [[0.00020575]], funcion objetivo: [[-647.76303132]]\n",
      "iteracion: 8, tK=1, cond. de parada: [[2.26287182e-05]], funcion objetivo: [[-647.76303891]]\n",
      "iteracion: 9, tK=1, cond. de parada: [[2.4551196e-06]], funcion objetivo: [[-647.76303973]]\n",
      "iteracion: 10, tK=1, cond. de parada: [[2.675745e-07]], funcion objetivo: [[-647.76303982]]\n",
      "iteracion: 11, tK=1, cond. de parada: [[2.91186781e-08]], funcion objetivo: [[-647.76303983]]\n",
      "------------------------------------------------------\n",
      "instancia 4 Metodo del gradiente con backtracking search\n",
      "------------------------------------------------------\n",
      "iteracion: 0, cond. de parada: 1413.6162265473672\n",
      "iteracion: 1, tK=0.0005454977230054827, cond. de parada: 217.55139143090298, funcion objetivo: [[-372.09635016]]\n",
      "iteracion: 2, tK=0.013083690825684025, cond. de parada: 45.45727973720429, funcion objetivo: [[-642.23450055]]\n",
      "iteracion: 3, tK=0.0926510094425921, cond. de parada: 2.545908525421985, funcion objetivo: [[-732.77884392]]\n",
      "iteracion: 4, tK=0.125, cond. de parada: 0.38852332049259836, funcion objetivo: [[-733.17346109]]\n",
      "iteracion: 5, tK=0.125, cond. de parada: 0.09209184597011695, funcion objetivo: [[-733.18418176]]\n",
      "iteracion: 6, tK=0.125, cond. de parada: 0.02619982395716926, funcion objetivo: [[-733.18484772]]\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "m = [50, 100, 200, 200, 400]\n",
    "n = [10, 50, 100, 200, 250]\n",
    "instancia = range(1,6)\n",
    "alfa = 0.3\n",
    "beta = 0.5\n",
    "for i in instancia:\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"instancia \"+str(i)+\" Metodo del gradiente con backtracking search\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    A = matrix(random.rand(m[i-1],n[i-1]))\n",
    "    X0 = matrix(zeros((n[i-1],1)))\n",
    "    XK = X0\n",
    "    # backtracking search method\n",
    "    gradiente_backtracking(A,X0,m[i-1],n[i-1],alfa,beta)\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"instancia \"+str(i)+\" Metodo de Newton con backtracking search\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    newton_backtracking(A,X0,m,n,alfa,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = matrix(zeros((2,1)))\n",
    "A[0,0] = 2\n",
    "A[1,0] = 1\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gradf2() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2616c2d6c411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: gradf2() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "gradf2(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
